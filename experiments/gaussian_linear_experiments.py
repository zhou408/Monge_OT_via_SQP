# -*- coding: utf-8 -*-
"""Gaussian -> Gaussian (Linear) notebook section.

Extracted from original notebook export on split date 2026-02-20.
This file intentionally keeps original logic, defaults, and analytic comparisons.
"""

import sys

# Entry policy for notebook-derived scripts:
# run heavy demo blocks only when explicitly requested.
_RUN_FULL_DEMO = ('--demo' in sys.argv and 'full' in sys.argv)
if __name__ == '__main__' and not _RUN_FULL_DEMO:
    print('This is a notebook-style experiment script.')
    print('Run with: python {} --demo full'.format(__file__))
    sys.exit(0)

# Ensure notebook-style unicode prints work on Windows terminals.
if hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8')
if hasattr(sys.stderr, 'reconfigure'):
    sys.stderr.reconfigure(encoding='utf-8')


# -*- coding: utf-8 -*-
"""SQP draft.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vUGhr5Yjj7JmO7ykybHDdxvXGW_Fym55

# Experiment Description

> This note extracts and explains the essentials you’ll need from **Section 1 (Densities & 95% domain)**, **Section 2 (Objective \(J\))**, and **Section 5 (Full SQP driver)** so you can read/annotate them in Google Colab. Math is in \(\LaTeX\), code names match the Python implementation.

* * *

## 1) Densities & 95% mass domain

### Gaussian PDF
For $x\in\mathbb{R}$, mean $\mu$, std $s>0$,
$$
\mathrm{NormalPDF}(x;\mu,s) \;=\; \frac{1}{s\sqrt{2\pi}}\,\exp\!\Big(-\frac{1}{2}\,\Big(\frac{x-\mu}{s}\Big)^2\Big).
$$
**Code:** `normal_pdf(x, mu, s)` (vectorized).

### 95% mass interval for two Gaussians
Given source $(\mu_0, s_0)$ and target $(\mu_1, s_1)$, a convenient shared grid covering ~95% probability mass of **both** distributions is
$$
L \;=\; \min\{\mu_0-1.96\,s_0,\;\mu_1-1.96\,s_1\},\qquad
R \;=\; \max\{\mu_0+1.96\,s_0,\;\mu_1+1.96\,s_1\}.
$$
**Code:** `domain_95(params, k=1.96)` returns $(L,R)$.\
**Grid:** `make_grid(params, m, L=None, R=None)` builds $m$ equally spaced points over $[L,R]$ and returns a `GridSpec` with fields $(L, R, m, points)$.

* * *

## 2) Objective $J(\kappa,\gamma,\beta)$ for the quadratic map

We parameterize a **monotone quadratic** transport $s:\mathbb{R}\to\mathbb{R}$ as
$$
s(x) \;=\; \kappa x^2 + \alpha x + \beta,\qquad \alpha \;=\; e^{\gamma} \;>\; 0,
$$
with variables $(\kappa,\gamma,\beta)\in\mathbb{R}^3$. Let $X\sim\mathcal N(\mu_0, s_0^2)$ be the **source** random variable. The (least-squares) fitting objective used here is
$$
J(\kappa,\gamma,\beta) \;=\; \frac{1}{2}\,\mathbb{E}\big[(X - s(X))^2\big].
$$

### Expansion with Gaussian raw moments
Define the residual
$$
r(X) \;=\; X - s(X) \;=\; -\kappa X^2 + (1-\alpha)X - \beta.
$$
Then
$$
\mathbb{E}[r(X)^2]
= \kappa^2\,\mathbb{E}[X^4] + (1-\alpha)^2\,\mathbb{E}[X^2] + \beta^2
- 2\kappa(1-\alpha)\,\mathbb{E}[X^3] + 2\kappa\beta\,\mathbb{E}[X^2] - 2(1-\alpha)\beta\,\mathbb{E}[X].
$$
For $X\sim\mathcal N(\mu_0,s_0^2)$, the **raw moments** are
$$
\begin{aligned}
\mathbb{E}[X] &= \mu_0,\\
\mathbb{E}[X^2] &= s_0^2 + \mu_0^2,\\
\mathbb{E}[X^3] &= \mu_0^3 + 3\mu_0 s_0^2,\\
\mathbb{E}[X^4] &= 3s_0^4 + 6\mu_0^2 s_0^2 + \mu_0^4.
\end{aligned}
$$
Hence $J = \tfrac12\,\mathbb{E}[r^2]$ can be computed **analytically** from $(\mu_0,s_0)$ and $(\kappa,\alpha,\beta)$.\
**Code:** `objective_J_kgb(kappa, gamma, beta, params)` implements this with $\alpha=e^\gamma$.

### Gradient and Hessian (closed forms)
Write the first derivatives in $(\kappa,\alpha,\beta)$:
$$
\begin{aligned}
\frac{\partial J}{\partial \kappa} &= \kappa\,\mathbb{E}[X^4] \;-\; (1-\alpha)\,\mathbb{E}[X^3] \;+\; \beta\,\mathbb{E}[X^2],\\
\frac{\partial J}{\partial \alpha} &= - (1-\alpha)\,\mathbb{E}[X^2] \;+\; \kappa\,\mathbb{E}[X^3] \;+\; \beta\,\mathbb{E}[X],\\
\frac{\partial J}{\partial \beta}  &= \beta \;-\; (1-\alpha)\,\mathbb{E}[X] \;+\; \kappa\,\mathbb{E}[X^2].
\end{aligned}
$$
Since $\alpha=e^\gamma$, the chain rule gives
$$
\frac{\partial J}{\partial \gamma} \;=\; \alpha\,\frac{\partial J}{\partial \alpha}.
$$
Second derivatives in $(\kappa,\alpha,\beta)$ are **constant** in parameters (depend only on moments):
$$
\frac{\partial^2 J}{\partial \kappa^2}=\mathbb{E}[X^4],\quad
\frac{\partial^2 J}{\partial \alpha^2}=\mathbb{E}[X^2],\quad
\frac{\partial^2 J}{\partial \beta^2}=1,
$$
$$
\frac{\partial^2 J}{\partial \kappa\,\partial \alpha}=\mathbb{E}[X^3],\quad
\frac{\partial^2 J}{\partial \kappa\,\partial \beta}=\mathbb{E}[X^2],\quad
\frac{\partial^2 J}{\partial \alpha\,\partial \beta}=\mathbb{E}[X].
$$
Transforming to $(\kappa,\gamma,\beta)$ via $\alpha=e^\gamma$ yields
$$
\begin{aligned}
\frac{\partial^2 J}{\partial \gamma^2} &= \alpha^2\,\frac{\partial^2 J}{\partial \alpha^2} \;+\; \alpha\,\frac{\partial J}{\partial \alpha},\\
\frac{\partial^2 J}{\partial \kappa\,\partial \gamma} &= \alpha\,\frac{\partial^2 J}{\partial \kappa\,\partial \alpha},\\
\frac{\partial^2 J}{\partial \beta\,\partial \gamma} &= \alpha\,\frac{\partial^2 J}{\partial \alpha\,\partial \beta}.
\end{aligned}
$$
**Code:** `grad_hess_J_kgb(...)` returns `(grad, Hess, Jval)` in the $(\kappa,\gamma,\beta)$ coordinates.

> **Why $\alpha=e^\gamma$?** It enforces $\alpha>0$ (useful for monotonicity of $s$ when $|\kappa|$ is small) and keeps the optimization unconstrained in $\gamma$.

* * *

## 5) Full SQP driver (3D) — how the solver runs

We solve the **equality-constrained** problem
$$
\min_{\kappa,\gamma,\beta}\ J(\kappa,\gamma,\beta)
\quad\text{s.t.}\quad
\zeta(d_j;\kappa,\gamma,\beta) \;=\; 0,\quad j=1,\dots,m,
$$
where on a grid $\{d_j\}_{j=1}^m$ we enforce **pushforward density matching**
$$
\zeta(d) \;=\; \frac{f\!\left( s^{-1}(d)\right)}{\left| s'\!\left( s^{-1}(d)\right)\right|} \;-\; g(d),
$$
with $f=\mathcal N(\mu_0,s_0^2)$ and $g=\mathcal N(\mu_1,s_1^2)$. The inverse $u=s^{-1}(d)$ is obtained via a **stable quadratic formula** with a root that is continuous as $\kappa\to 0$ (affine limit).

### SQP iterate (one step)
At $(x,\lambda)=(\kappa,\gamma,\beta,\lambda)$, form the (regularized) KKT system
$$
\begin{bmatrix}
H+\rho_p I & A^\top \\
A & -\rho_d I
\end{bmatrix}
\begin{bmatrix}
d \\ w
\end{bmatrix}
\;=\;
-\begin{bmatrix}
g \\ \zeta
\end{bmatrix},
$$
where:
- $g = \nabla J + A^\top\lambda$ (Lagrangian gradient),
- $H$ is the Lagrangian Hessian (default: **objective Hessian** only for efficiency),
- $A = \frac{\partial \zeta}{\partial (\kappa,\gamma,\beta)}$ via **finite differences**,  
- $\rho_p\ge 0$ and $\rho_d>0$ are small regularizers.

Update
$$
x^{+} = x + d, \qquad \lambda^{+} = \lambda + w.
$$

### Driver loop (what `sqp_solve_quadratic` does)
1. Build grid `GridSpec` with `make_grid(...)` (default: 95% mass interval, $m$ points).
2. Initialize $(\kappa,\gamma,\beta)$ and $\lambda$.
3. For `it=1..max_iter`:
   - Compute `Jval`, residuals $\zeta$, and $g,A,H$.
   - Check convergence: $\|g\|*{\infty}\le \texttt{tol\_opt}$ **and** $\|\zeta\|*{\infty}\le \texttt{tol\_feas}$.
   - Solve the KKT system for $(d,w)$ (least-squares).
   - Optional **trust clipping**: if $\|d\|_\infty>\texttt{trust\_clip}$, scale down $d$.
   - Update $(x,\lambda)$ and log the history.
4. Return $(\kappa,\gamma,\beta,\alpha=e^\gamma)$, $\lambda$, the grid, and iteration history (for plotting/diagnostics).

### Practical tips
- Use moderate grid sizes initially (e.g., $m=101$–$201$).
- Keep a small dual regularizer $\rho_d$ (e.g., $10^{-8}$) to stabilize the KKT solve.
- If steps explode, set `trust_clip` (e.g., $0.25$–$0.5$) and/or increase $m$.
- For Gaussian$\to$Gaussian under quadratic cost, the optimum is **affine** ($\kappa^*=0$), so you should see $\kappa\to 0$ and $(\alpha,\beta)$ approaching the closed form $\alpha^*=\frac{s_1}{s_0}$, $\beta^*=\mu_1-\alpha^*\mu_0$.

#Linear Solution Space

## Code
"""

# SQP for 1D Gaussian OT with linear map s(x)=alpha x + beta, using alpha = exp(gamma)
# Modules are separated so you can test each component in Colab step-by-step.
# A small demo at the bottom runs basic checks and a full SQP solve.
#
# Author:

from dataclasses import dataclass
from typing import Tuple, Dict, Optional
import numpy as np


# ==========================
# Module 0: Problem Params
# ==========================

@dataclass
class OTParams:
    mu0: float      # source mean
    s0: float       # source std (sigma_0)
    mu1: float      # target mean
    s1: float       # target std (sigma_1)

@dataclass
class GridSpec:
    L: float
    R: float
    m: int
    points: np.ndarray  # shape (m,)


# ===========================================
# Module 1: Densities & 95% mass domain
# ===========================================

def normal_pdf(x: np.ndarray, mu: float, s: float) -> np.ndarray:
    """Standard normal density with mean mu, std s (vectorized)."""
    z = (x - mu) / s
    return np.exp(-0.5 * z * z) / (s * np.sqrt(2.0 * np.pi))

def domain_95(params: OTParams, k: float = 1.96) -> Tuple[float, float]:
    """Return [L, R] covering at least 95% mass of both Gaussians."""
    L = min(params.mu0 - k * params.s0, params.mu1 - k * params.s1)
    R = max(params.mu0 + k * params.s0, params.mu1 + k * params.s1)
    return L, R

def make_grid(params: OTParams, m: int, L: Optional[float] = None, R: Optional[float] = None) -> GridSpec:
    if L is None or R is None:
        L2, R2 = domain_95(params)
        if L is None: L = L2
        if R is None: R = R2
    pts = np.linspace(L, R, m)
    return GridSpec(L=L, R=R, m=m, points=pts)


# =====================================================
# Module 2: Objective J in (gamma, beta) coordinates
# =====================================================

def objective_J_alpha_beta(alpha: float, beta: float, params: OTParams) -> float:
    """Closed-form objective J(alpha, beta) for 1D Gaussian source and quadratic cost."""
    mu0, s0 = params.mu0, params.s0
    E_X2 = s0**2 + mu0**2
    # J = 1/2 * E_f ( ((1-alpha)X - beta)^2 )
    return 0.5 * ((1 - alpha)**2 * E_X2 - 2 * beta * (1 - alpha) * mu0 + beta**2)

def grad_hess_J_gamma_beta(gamma: float, beta: float, params: OTParams) -> Tuple[np.ndarray, np.ndarray, float]:
    """
    Gradient and Hessian of J with respect to (gamma, beta), where alpha = exp(gamma).
    Returns (grad[2], Hess[2,2], J).
    """
    mu0, s0 = params.mu0, params.s0
    E_X2 = s0**2 + mu0**2

    alpha = np.exp(gamma)

    # Partials in (alpha, beta)
    dJ_dalpha = -(1 - alpha) * E_X2 + beta * mu0
    dJ_dbeta  = -(1 - alpha) * mu0 + beta

    # Chain rule for (gamma, beta)
    dJ_dgamma = alpha * dJ_dalpha  # alpha' = alpha
    grad = np.array([dJ_dgamma, dJ_dbeta])

    # Hessian blocks
    # d2J/dgamma2 = alpha^2 * d2J/dalpha2 + alpha * dJ/dalpha
    d2J_dalpha2 = E_X2
    d2J_dgamma2 = (alpha**2) * d2J_dalpha2 + alpha * dJ_dalpha

    # d2J/dgamma dbeta = alpha * d2J/dalpha dbeta = alpha * mu0
    d2J_dgamma_dbeta = alpha * mu0

    # d2J/dbeta2 = 1
    d2J_dbeta2 = 1.0

    Hess = np.array([[d2J_dgamma2, d2J_dgamma_dbeta],
                     [d2J_dgamma_dbeta, d2J_dbeta2]])

    # J value
    Jval = objective_J_alpha_beta(alpha, beta, params)
    return grad, Hess, Jval


# ==================================================================
# Module 3: Constraint zeta (pushforward density match) on a grid
#           and its Jacobian/Hessian in (gamma, beta)
# ==================================================================

def constraint_zeta_gamma_beta(
    gamma: float,
    beta: float,
    grid: GridSpec,
    params: OTParams,
    compute_hessian: bool = False
) -> Dict[str, np.ndarray]:
    """
    Compute zeta (size m), its Jacobian A (m x 2) wrt (gamma, beta),
    and optionally exact Hessians list Hlist where Hlist[j] is 2x2 Hessian of zeta_j.
    """
    mu0, s0 = params.mu0, params.s0
    mu1, s1 = params.mu1, params.s1
    d = grid.points
    m = grid.m

    alpha = np.exp(gamma)  # > 0

    # u_j = (d_j - beta)/alpha
    u = (d - beta) / alpha
    Delta = u - mu0 # helper variable, how far the preimage u is from the source mean.

    f_u = normal_pdf(u, mu0, s0)
    g_d = normal_pdf(d, mu1, s1)

    # zeta_j = (1/alpha) f(u) - g(d)
    zeta = (1.0 / alpha) * f_u - g_d

    # First derivatives wrt (gamma, beta)
    # d zeta / d gamma = alpha * d zeta / d alpha
    # Using derived formula: d zeta / d gamma = -(f(u)/alpha) * [1 - (u*Delta)/s0^2]
    A = np.zeros((m, 2))

    # Precompute helpful terms
    inv_s0_2 = 1.0 / (s0**2)
    uDelta_over_s0_2 = u * Delta * inv_s0_2

    dzetadgamma = -(f_u / alpha) * (1.0 - uDelta_over_s0_2)
    dzetadbeta  = (Delta * inv_s0_2) * (f_u / (alpha**2))

    A[:, 0] = dzetadgamma
    A[:, 1] = dzetadbeta

    if not compute_hessian:
        return {"zeta": zeta, "A": A}

    # Second derivatives (exact), each zeta_j has a 2x2 Hessian
    # We use the explicit expressions derived earlier.
    # f''(u) = ((Delta^2 - s0^2)/s0^4) * f(u)
    # Explicit mapped second derivatives to (gamma, beta):
    # d2 zeta / d gamma^2
    d2zetadgamma2 = (f_u / alpha) * (
        1.0 - 3.0 * (u * Delta) * inv_s0_2 + (u**2) * ((Delta**2 - s0**2) * (inv_s0_2**2))
    )
    # d2 zeta / d gamma d beta
    d2zetadgamma_dbeta = -(f_u / (alpha**2) * inv_s0_2) * (
        u * (1.0 - (Delta**2) * inv_s0_2) + 2.0 * Delta
    )
    # d2 zeta / d beta^2
    d2zetadb2 = -(f_u / (alpha**3)) * ((s0**2 - Delta**2) * (inv_s0_2**2))

    Hlist = []
    for j in range(m):
        Hj = np.array([[d2zetadgamma2[j], d2zetadgamma_dbeta[j]],
                       [d2zetadgamma_dbeta[j], d2zetadb2[j]]])
        Hlist.append(Hj)

    return {"zeta": zeta, "A": A, "H": Hlist}


# ===============================================================
# Module 4: One SQP step (build KKT, solve for search direction)
# ===============================================================

def build_lagrangian_terms(
    gamma: float,
    beta: float,
    lam: np.ndarray,
    grid: GridSpec,
    params: OTParams,
    use_exact_constraint_hess: bool = False
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, float]:
    """
    Build gradient (g), Hessian (H), Jacobian (A) of the Lagrangian.
    Returns g (2,), H(2,2), A(m,2), and objective value J.
    """
    # Objective pieces
    gJ, HJ, Jval = grad_hess_J_gamma_beta(gamma, beta, params)

    # Constraints
    parts = constraint_zeta_gamma_beta(gamma, beta, grid, params, compute_hessian=use_exact_constraint_hess)
    zeta, A = parts["zeta"], parts["A"]

    # Lagrangian gradient: g = grad J + sum_j lam_j * grad zeta_j
    g = gJ + A.T @ lam

    # Lagrangian Hessian: H = HJ + sum_j lam_j * H_zeta_j (optional exact)
    if use_exact_constraint_hess:
        H = HJ.copy()
        for j in range(grid.m):
            H += lam[j] * parts["H"][j]
    else:
        H = HJ

    return g, H, A, Jval

def sqp_step(
    gamma: float,
    beta: float,
    lam: np.ndarray,
    grid: GridSpec,
    params: OTParams,
    use_exact_constraint_hess: bool = False,
    reg_H: float = 1e-10,
    reg_KKT_primal: float = 0.0,
    reg_KKT_dual: float = 1e-8
):
    """
    SQP step with small diagonal damping on both H and the (0) block (dual side).
    """
    # Build terms
    g, H, A, Jval = build_lagrangian_terms(
        gamma, beta, lam, grid, params, use_exact_constraint_hess=use_exact_constraint_hess
    )
    zeta = constraint_zeta_gamma_beta(gamma, beta, grid, params)["zeta"]

    m = grid.m
    # Regularize both primal Hessian block and dual (constraint) block
    H_reg = H + reg_H * np.eye(2)
    K = np.block([
        [H_reg + reg_KKT_primal * np.eye(2), A.T],
        [A, -reg_KKT_dual * np.eye(m)]
    ])
    rhs = -np.concatenate([g, zeta])

    sol = np.linalg.lstsq(K, rhs, rcond=None)[0]  # robust solve
    d = sol[:2]
    w = sol[2:]

    gamma_new = gamma + d[0]
    beta_new  = beta  + d[1]
    lam_new   = lam + w

    opt_res = np.linalg.norm(g, ord=np.inf)
    feas_res = np.linalg.norm(zeta, ord=np.inf)
    return np.array([gamma_new, beta_new]), lam_new, d, opt_res, feas_res

# =====================================
# Module 5: Full SQP driver
# =====================================

def sqp_solve(
    params: OTParams,
    m: int = 21,
    max_iter: int = 50,
    tol_opt: float = 1e-8,
    tol_feas: float = 1e-8,
    use_exact_constraint_hess: bool = False,
    init_gamma: float = 0.0,
    init_beta: float = 0.0,
    L: Optional[float] = None,
    R: Optional[float] = None,
    trust_clip: Optional[float] = None,
) -> Dict[str, np.ndarray]:
    grid = make_grid(params, m=m, L=L, R=R)
    gamma, beta = init_gamma, init_beta
    lam = np.zeros(grid.m)

    hist = {"gamma": [], "beta": [], "alpha": [], "J": [], "opt_res": [], "feas_res": []}

    for it in range(max_iter):
        alpha = np.exp(gamma)
        _, _, Jval = grad_hess_J_gamma_beta(gamma, beta, params)
        zeta_now = constraint_zeta_gamma_beta(gamma, beta, grid, params)["zeta"]
        g_now, H_now, A_now, _ = build_lagrangian_terms(gamma, beta, lam, grid, params, use_exact_constraint_hess)

        hist["gamma"].append(gamma); hist["beta"].append(beta); hist["alpha"].append(alpha); hist["J"].append(Jval)
        hist["opt_res"].append(np.linalg.norm(g_now, np.inf)); hist["feas_res"].append(np.linalg.norm(zeta_now, np.inf))

        if hist["opt_res"][-1] <= tol_opt and hist["feas_res"][-1] <= tol_feas:
            break

        gamma_beta_new, lam_new, d, opt_res, feas_res = sqp_step(
            gamma, beta, lam, grid, params,
            use_exact_constraint_hess=use_exact_constraint_hess,
            reg_H=1e-10, reg_KKT_primal=0.0, reg_KKT_dual=1e-8
        )

        if trust_clip is not None:
            step_norm_inf = np.linalg.norm(d, np.inf)
            if step_norm_inf > trust_clip:
                d = d * (trust_clip / step_norm_inf)
                gamma_beta_new = np.array([gamma, beta]) + d

        gamma, beta = gamma_beta_new[0], gamma_beta_new[1]
        lam = lam_new

    return {"gamma": gamma, "beta": beta, "alpha": np.exp(gamma), "lambda": lam, "grid": grid, "history": hist}


# ==================================================
# Module 6: Finite-difference checks (unit tests)
# ==================================================

def finite_diff_grad(fun, x: np.ndarray, eps: float = 1e-6) -> np.ndarray:
    """Simple central-difference gradient estimator."""
    g = np.zeros_like(x)
    for i in range(len(x)):
        dx = np.zeros_like(x)
        dx[i] = eps
        g[i] = (fun(x + dx) - fun(x - dx)) / (2 * eps)
    return g

def finite_diff_hess(fun, x: np.ndarray, eps: float = 1e-5) -> np.ndarray:
    """Simple central-difference Hessian estimator (O(n^2))."""
    n = len(x)
    H = np.zeros((n, n))
    for i in range(n):
        for j in range(n):
            ei = np.zeros(n); ei[i] = eps
            ej = np.zeros(n); ej[j] = eps
            H[i, j] = (
                fun(x + ei + ej) - fun(x + ei - ej)
                - fun(x - ei + ej) + fun(x - ei - ej)
            ) / (4 * eps * eps)
    return H


# =====================================
# Demo / Self-tests (safe to run)
# =====================================

if __name__ == "__main__":
    np.set_printoptions(precision=6, suppress=True)

    # Test parameters: nontrivial Gaussian-to-Gaussian
    params = OTParams(mu0=0.7, s0=1.3, mu1=-0.4, s1=0.8)

    # Ground-truth OT map (for quadratic cost, 1D): s*(x) = a* x + b with
    a_star = params.s1 / params.s0
    b_star = params.mu1 - a_star * params.mu0

    print("=== Ground truth (analytical) for affine OT ===")
    print(f"alpha* = {a_star:.6f}, beta* = {b_star:.6f}\n")

    # ----- Test Module 2: J, grad, Hess in (gamma, beta) -----
    gamma0 = 0.0   # alpha=1
    beta0  = 0.0
    gradJ, HJ, Jval = grad_hess_J_gamma_beta(gamma0, beta0, params)
    print("Module 2: Objective J at (gamma=0, beta=0)")
    print("J =", Jval)
    print("grad J =", gradJ)
    print("Hess J =\n", HJ, "\n")

    # Finite-diff check for J
    def fun_J_gb(x):
        g, b = x
        _, _, Jv = grad_hess_J_gamma_beta(g, b, params)
        return Jv

    x0 = np.array([gamma0, beta0])
    g_fd = finite_diff_grad(fun_J_gb, x0)
    H_fd = finite_diff_hess(fun_J_gb, x0)
    print("FD grad J @ (0,0):", g_fd)
    print("FD Hess J @ (0,0):\n", H_fd, "\n")

    # ----- Test Module 3: Constraints zeta, Jacobian, Hessians -----
    grid = make_grid(params, m=17)  # modest grid
    parts = constraint_zeta_gamma_beta(gamma0, beta0, grid, params, compute_hessian=True)
    print("Module 3: Constraint zeta at (gamma=0, beta=0) -- shapes:")
    print("zeta shape:", parts["zeta"].shape, "A shape:", parts["A"].shape, "H list len:", len(parts["H"]), "\n")

    # Finite-diff check for a single constraint component zeta_j
    j = grid.m // 2
    def fun_zeta_j(x):
        g, b = x
        out = constraint_zeta_gamma_beta(g, b, grid, params, compute_hessian=False)
        return out["zeta"][j]
    g_fd_zj = finite_diff_grad(fun_zeta_j, x0)
    H_fd_zj = finite_diff_hess(fun_zeta_j, x0)
    print(f"FD grad zeta[{j}] @ (0,0):", g_fd_zj)
    print(f"FD Hess zeta[{j}] @ (0,0):\n{H_fd_zj}\n")
    print("Analytic grad zeta[j]:", parts["A"][j])
    print("Analytic Hess zeta[j]:\n", parts["H"][j], "\n")

    # ----- Test Module 5: Full SQP solve -----
    print("=== Running SQP (no line search) ===")
    sol = sqp_solve(
        params,
        m=31,
        max_iter=30,
        tol_opt=1e-10,
        tol_feas=1e-10,
        use_exact_constraint_hess=False,  # try True as well
        init_gamma=0.0,
        init_beta=0.0,
        trust_clip=0.5  # optional safeguard
    )

    print("Solved (gamma, beta):", sol["gamma"], sol["beta"])
    print("Solved alpha:", sol["alpha"])
    print("History last opt_res, feas_res:", sol["history"]["opt_res"][-1], sol["history"]["feas_res"][-1])
    print("\nCompare to analytic OT: alpha*={:.6f}, beta*={:.6f}".format(a_star, b_star))

# Run the solver
# params = OTParams(mu0=0.7, s0=1.3, mu1=-0.4, s1=0.8)
params = OTParams(mu0=0.7, s0=4, mu1=-0.3, s1=8)
a_star = params.s1 / params.s0
b_star = params.mu1 - a_star * params.mu0

print("=== Patched SQP run (damped KKT) ===")
sol2 = sqp_solve(params, m=31, max_iter=50, trust_clip=0.5, use_exact_constraint_hess=False)
print("Solved alpha:", sol2["alpha"], "beta:", sol2["beta"])
print("Compare to analytic alpha*, beta*:", a_star, b_star)
print("Final opt, feas:", sol2["history"]["opt_res"][-1], sol2["history"]["feas_res"][-1])

print(sol2["history"].keys())

"""## Plot"""

# Utility to build & display the composite (top p(x), left q(y), middle transport plan).
# It will both SAVE to disk and DISPLAY inline.
#
# You can tweak:
#   - use_sqp: True -> center uses SQP map; False -> analytic affine map
#   - save_path: where to save the stitched image
#   - params: OTParams(...) for source/target Gaussians
#   - fixed_domain: tuple (a,b) used for the *top x-limits* and *left y-limits*
#   - heatmap_xrange / heatmap_yrange: tuples that set the heatmap axes range.
#       Example: (-1,1) and (-1,1) to force a fixed square. If None, uses combined domain.
#   - bins: 2D histogram bins for the heatmap
#
# Output:
#   - Displays the composite inline
#   - Returns the save path string

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# from sqp_ot_1d import OTParams, make_grid, normal_pdf, sqp_solve

def plot_ot_composite(
    use_sqp: bool = False,
    save_path: str = "ot_composite_colab.png",
    params: OTParams = OTParams(mu0=-1.4, s0=2.2, mu1=0.6, s1=1.25),
    fixed_domain = (-1.0, 1.0),
    heatmap_xrange = None,   # e.g., (-1, 1)
    heatmap_yrange = None,   # e.g., (-1, 1)
    bins: int = 200,
):
    # ----- choose the map for the center -----
    sol = sqp_solve(params, m=41, max_iter=60, trust_clip=0.5)
    if use_sqp:
        alpha_c = sol["alpha"]
        beta_c  = sol["beta"]
    else:
        alpha_c = params.s1 / params.s0
        beta_c  = params.mu1 - alpha_c * params.mu0

    # ----- domains -----
    # combined domain for default heatmap axes
    grid = make_grid(params, m=401)
    Lc, Rc = grid.L, grid.R

    # fixed ranges for the density panels
    x_min_fix, x_max_fix = fixed_domain
    y_min_fix, y_max_fix = fixed_domain

    # heatmap ranges (fall back to combined domain if not provided)
    hx_min, hx_max = (heatmap_xrange if heatmap_xrange is not None else (Lc, Rc))
    hy_min, hy_max = (heatmap_yrange if heatmap_yrange is not None else (Lc, Rc))

    # ----- sample for center plan -----
    rng = np.random.default_rng(123)
    N = 30_000
    X = rng.normal(params.mu0, params.s0, size=N)
    Y = alpha_c * X + beta_c

    # ----- MAIN HEATMAP with your chosen range -----
    H, xe, ye = np.histogram2d(
        X, Y,
        bins=bins,
        range=[[hx_min, hx_max], [hy_min, hy_max]]
    )

    main_w, main_h = 800, 800
    plt.figure(figsize=(main_w/100, main_h/100), dpi=100)
    plt.imshow(
        H.T, origin="lower",
        extent=[hx_min, hx_max, hy_min, hy_max],  # <- fixed heatmap axes here
        aspect="auto"
    )
    plt.xlabel("x")
    plt.ylabel("y")
    plt.tight_layout(pad=0.6)
    main_path = "_panel_main_colab.png"
    plt.savefig(main_path, dpi=100)
    plt.close()

    # ----- TOP SOURCE DENSITY on physical x with FIXED LIMITS -----
    x = np.linspace(x_min_fix, x_max_fix, 600)
    p = normal_pdf(x, params.mu0, params.s0)
    top_w, top_h = main_w, 240
    plt.figure(figsize=(top_w/100, top_h/100), dpi=100)
    plt.plot(x, p)
    plt.xlim(x_min_fix, x_max_fix)   # <- fixed x-limits for top panel
    plt.title("source density p(x)")
    plt.xlabel("")   # hide labels (keep title)
    plt.ylabel("")
    plt.tight_layout(pad=0.6)
    top_path = "_panel_top_colab.png"
    plt.savefig(top_path, dpi=100)
    plt.close()

    # ----- LEFT TARGET DENSITY on physical y with FIXED LIMITS
    # y-axis on RIGHT; x-axis REVERSED so the curve points LEFT; y increases bottom->top -----
    y = np.linspace(y_min_fix, y_max_fix, 600)
    q = normal_pdf(y, params.mu1, params.s1)
    left_w, left_h = 240, main_h
    fig = plt.figure(figsize=(left_w/100, left_h/100), dpi=100)
    ax = fig.add_subplot(111)
    ax.plot(q, y)                       # q(y) horizontally vs y vertically
    ax.invert_xaxis()                   # <- reverse x-axis (larger density to the LEFT)
    ax.set_ylim(y_min_fix, y_max_fix)   # <- fixed vertical span; do NOT invert y
    ax.set_title("target density q(y)")
    ax.set_xlabel("")
    ax.set_ylabel("")
    ax.yaxis.tick_right()
    ax.yaxis.set_label_position("right")
    ax.spines['left'].set_visible(False)
    ax.spines['right'].set_visible(True)
    fig.tight_layout(pad=0.6)
    left_path = "_panel_left_colab.png"
    fig.savefig(left_path, dpi=100)
    plt.close(fig)

    # ----- STITCH PANELS -----
    img_main = Image.open(main_path)
    img_top  = Image.open(top_path)
    img_left = Image.open(left_path)

    canvas_w = left_w + main_w
    canvas_h = top_h + main_h
    canvas = Image.new("RGB", (canvas_w, canvas_h), (255, 255, 255))

    pos_top  = (left_w, 0)
    pos_left = (0, top_h)
    pos_main = (left_w, top_h)

    canvas.paste(img_top,  pos_top)
    canvas.paste(img_left, pos_left)
    canvas.paste(img_main, pos_main)

    canvas.save(save_path)

    # ----- DISPLAY INLINE -----
    plt.figure(figsize=(canvas_w/100, canvas_h/100), dpi=100)
    plt.imshow(canvas)
    plt.axis("off")
    plt.tight_layout(pad=0.0)
    plt.show()

    return save_path


# Example run:
#   * fixed top/left limits: [-1, 1]
#   * fixed heatmap box:     [-1, 1] x [-1, 1]
final_path = plot_ot_composite(
    use_sqp=True,
    save_path="ot_composite_colab.png",
    params=OTParams(mu0=-1.4, s0=2.2, mu1=0.6, s1=1.25),
    fixed_domain=(-8, 8),
    heatmap_xrange=(-8, 8),
    heatmap_yrange=(-8, 8),
    bins=200
)
print(final_path)

import numpy as np
import matplotlib.pyplot as plt
# from sqp_ot_1d import OTParams, make_grid, sqp_solve

# --- Set your problem ---
params = OTParams(mu0=-1.4, s0=2.2, mu1=0.6, s1=1.25)
# params = OTParams(mu0=-0.6, s0=3.4, mu1=1.7, s1=2.85)

# --- Adjustable plot ranges (set to None to auto) ---
X_RANGE = (-8.0, 8.0)          # e.g. (-1.0, 1.0) or None to use combined 95% domain
Y_RANGE = None          # e.g. (-1.0, 1.0) or None to auto from the lines

# --- Output file path ---
SAVE_PATH = "transport_maps.png"   # e.g. "/content/transport_maps.png" on Colab

# --- Compute analytic and SQP maps ---
alpha_star = params.s1 / params.s0
beta_star  = params.mu1 - alpha_star * params.mu0

sol = sqp_solve(params, m=10, max_iter=60, trust_clip=0.5)
alpha_hat, beta_hat = sol["alpha"], sol["beta"]

# --- Choose x-range for plotting ---
if X_RANGE is None:
    grid = make_grid(params, m=401)
    xmin, xmax = grid.L, grid.R
else:
    xmin, xmax = X_RANGE

xs = np.linspace(xmin, xmax, 500)
ys_analytic = alpha_star * xs + beta_star
ys_sqp      = alpha_hat * xs + beta_hat

# --- Choose y-range (auto or fixed) ---
if Y_RANGE is None:
    ymin = min(ys_analytic.min(), ys_sqp.min())
    ymax = max(ys_analytic.max(), ys_sqp.max())
    pad = 0.05 * (ymax - ymin + 1e-12)
    ylo, yhi = ymin - pad, ymax + pad
else:
    ylo, yhi = Y_RANGE

# --- Plot (single figure, no custom colors) ---
plt.figure(figsize=(8, 6), dpi=120)
plt.plot(xs, ys_analytic, linewidth=2, label="Analytic: y = α* x + β*")
plt.plot(xs, ys_sqp, linestyle="--", linewidth=2, label="SQP: y = α x + β")
plt.xlim(xmin, xmax)
plt.ylim(ylo, yhi)
plt.xlabel("x")
plt.ylabel("y = s(x)")
plt.title("Transport maps: Analytic vs SQP")
plt.legend()
plt.tight_layout()

# ---- Save then show ----
plt.savefig(SAVE_PATH, dpi=200)   # <--- save line
plt.show()

print("Saved to:", SAVE_PATH)

