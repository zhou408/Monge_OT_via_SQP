# -*- coding: utf-8 -*-
"""Exponential -> Exponential notebook section.

Extracted from original notebook export on split date 2026-02-20.
This file intentionally keeps original logic, defaults, and analytic comparisons.
"""

import sys

# Entry policy for notebook-derived scripts:
# run heavy demo blocks only when explicitly requested.
_RUN_FULL_DEMO = ('--demo' in sys.argv and 'full' in sys.argv)
if __name__ == '__main__' and not _RUN_FULL_DEMO:
    print('This is a notebook-style experiment script.')
    print('Run with: python {} --demo full'.format(__file__))
    sys.exit(0)

# Ensure notebook-style unicode prints work on Windows terminals.
if hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8')
if hasattr(sys.stderr, 'reconfigure'):
    sys.stderr.reconfigure(encoding='utf-8')


# -*- coding: utf-8 -*-
"""Other SQP experiments.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ks1peipxajA60Lj0Humpb-9o06o4F25D

# Experiment Description

> This note extracts and explains the essentials you’ll need from **Section 1 (Densities & 95% domain)**, **Section 2 (Objective $J$**, and **Section 5 (Full SQP driver)** so you can read/annotate them in Google Colab. Math is in $LaTeX$, code names match the Python implementation. This notebook adapts the original Gaussian to Gaussian, quadratic cost problem to explore Exponential to Exponential and Gaussian to Exponential transport problems, using a piecewise-linear map for the latter.

* * *

## 1) Densities & Domains

### Gaussian PDF
For $x\in\mathbb{R}$, mean $\mu$, std $s>0$,
$$
\mathrm{NormalPDF}(x;\mu,s) \;=\; \frac{1}{s\sqrt{2\pi}}\,\exp\!\Big(-\frac{1}{2}\,\Big(\frac{x-\mu}{s}\Big)^2\Big).
$$
**Code:** `normal_pdf(x, mu, s)` (vectorized).

### Exponential PDF
For $x\ge 0$, rate $\lambda>0$,
$$
\mathrm{ExpPDF}(x;\lambda) \;=\; \lambda\,e^{-\lambda x}.
$$
**Code:** `exp_pdf(x, lam)` (vectorized).

### Domains
- **Gaussian:** A convenient shared grid covering ~95% probability mass is $[L, R] = [\mu \mp 1.96s]$. **Code:** `domain_gauss95(params, k=1.96)`.
- **Exponential:** A domain covering a high percentage of mass (e.g., 99.5%) is $[0, R]$ where $R = -\log(1-p)/\lambda$. **Code:** `exp_domain_mass(params, p=0.995)`.
- **Grids:** `make_xgrid(...)` and `make_dgrid(...)` build equally spaced points over specified intervals.

* *TGithub
*

## 2) Objectives $J$

The objective is generally $J = \tfrac12\,\mathbb{E}[(X - s(X))^2]$, but its form and computation depend on the source distribution and the map parameterization.

### Exponential Source, Quadratic Map ($s(x) = \alpha x + \beta$ with $\alpha=e^\gamma$)
For $X \sim \mathcal N(\mu_0, s_0^2)$, the objective can be computed analytically using raw moments (as in the original note).
For $X \sim \mathrm{Exp}(\lambda_0)$, the objective $J(\gamma, \beta)$ is also computed analytically.
**Code:** `objective_J_alpha_beta_exp`, `grad_hess_J_gamma_beta_exp`.

### Gaussian Source, Piecewise-Linear Map ($s(x)$ defined by knots and slopes)
The objective $J(\theta)$ is computed using numerical quadrature on the x-grid. The parameters $\theta$ are the log-slopes and the initial y-intercept.
**Code:** `objective_J(...)` for Gaussian to Exponential case.

* * *

## 5) Full SQP driver

We solve the **equality-constrained** problem
$$
\min_{\theta}\ J(\theta)
\quad\text{s.t.}\quad
\zeta(d_j;\theta) \;=\; 0,\quad j=1,\dots,m,
$$
where on a grid $\{d_j\}_{j=1}^m$ we enforce **pushforward density matching**
$$
\zeta(d) \;=\; \frac{f\!\left( s^{-1}(d)\right)}{\left| s'\!\left( s^{-1}(d)\right)\right|} \;-\; g(d),
$$
with $f$ the source density and $g$ the target density.

### SQP iterate (one step)
At $(x,\lambda)=(\theta,\lambda)$, form the (regularized) KKT system
$$
\begin{bmatrix}
H+\rho_p I & A^\top \\
A & -\rho_d I
\end{bmatrix}
\begin{bmatrix}
d_{\theta} \\
w
\end{bmatrix}
\;=\;
-\begin{bmatrix}
g \\
\zeta
\end{bmatrix},
$$
where:
- $g = \nabla J + A^\top\lambda$ (Lagrangian gradient),
- $H$ is the Lagrangian Hessian (default: **objective Hessian** only for efficiency),
- $A = \frac{\partial \zeta}{\partial \theta}$ via **finite differences** (Exponential case) or **analytic calculation** (Gaussian to Exponential case),
- $\rho_p\ge 0$ and $\rho_d>0$ are small regularizers.

Update
$$
\theta^{+} = \theta + d_{\theta}, \qquad \lambda^{+} = \lambda + w.
$$

### Driver loop (`sqp_solve_exp`, `sqp_solve_g2e`)
1. Build appropriate grids (`ExpGridSpec`, `XGrid`, `DGrid`).
2. Initialize parameters $(\kappa,\gamma,\beta)$ or $(\theta)$ and $\lambda$.
3. For `it=1..max_iter`:
   - Compute `Jval`, residuals $\zeta$, and $g,A,H$.
   - Check convergence: $\|g\|_\infty\le \texttt{tol\_opt}$ **and** $\|\zeta\|_\infty\le \texttt{tol\_feas}$.
   - Solve the KKT system for $(d_{\theta},w)$ (least-squares).
   - Optional **trust clipping**: if $\|d_{\theta}\|_\infty>\texttt{trust\_clip}$, scale down $d_{\theta}$.
   - Update $(\theta,\lambda)$ and log the history.
4. Return the learned map parameters, $\lambda$, grids, and iteration history.

### Practical tips
- Use moderate grid sizes initially.
- Keep a small dual regularizer $\rho_d$ (e.g., $10^{-8}$) to stabilize the KKT solve.
- If steps explode, set `trust_clip` (e.g., $0.25$–$0.5$).
- For the Gaussian to Exponential case, the piecewise-linear map requires careful handling of the inverse and its derivative.

# Exponential to Exponential

For the Exponential to Exponential transport problem with a quadratic map $s(x) = \alpha x + \beta$ (where $\alpha = e^\gamma$), the objective function $J(\gamma, \beta)$ is given by:

$$
J(\gamma, \beta) = \frac{1}{2} \mathbb{E}[(X - s(X))^2]
$$

where $X \sim \mathrm{Exp}(\lambda_0)$. Substituting $s(X)$ and using the raw moments of the Exponential distribution, this expands to an analytical expression in terms of $\alpha$, $\beta$, and $\lambda_0$.

**Differentiability:** Since the objective function has a closed-form analytical expression involving polynomials and the exponential function (which are infinitely differentiable), the objective function $J(\gamma, \beta)$ is twice differentiable (in fact, it is infinitely differentiable) with respect to its parameters $\gamma$ and $\beta$.

**Hessian:** The Hessian matrix of $J(\gamma, \beta)$ is the matrix of its second partial derivatives:

$$
H = \begin{bmatrix}
\frac{\partial^2 J}{\partial \gamma^2} & \frac{\partial^2 J}{\partial \gamma \partial \beta} \\
\frac{\partial^2 J}{\partial \beta \partial \gamma} & \frac{\partial^2 J}{\partial \beta^2}
\end{bmatrix}
$$

As shown in the code (`grad_hess_J_gamma_beta_exp`), these second partial derivatives are computed analytically. The analytical Hessian is used in the SQP method to find the optimal map parameters.
"""

from dataclasses import dataclass
from typing import Optional

import matplotlib.pyplot as plt
import numpy as np


@dataclass
class ExpParams:
    lam0: float  # source rate
    lam1: float  # target rate


@dataclass
class ExpGridSpec:
    L: float
    R: float
    m: int
    points: np.ndarray


def exp_pdf(x: np.ndarray, lam: float) -> np.ndarray:
    out = np.zeros_like(x, dtype=float)
    mask = x >= 0.0
    out[mask] = lam * np.exp(-lam * x[mask])
    return out


def exp_domain_mass(lam_or_params, p: float = 0.999) -> tuple[float, float]:
    if isinstance(lam_or_params, ExpParams):
        lam = min(lam_or_params.lam0, lam_or_params.lam1)
    else:
        lam = float(lam_or_params)
    return 0.0, float(-np.log(1.0 - p) / lam)


def make_exp_grid(params: ExpParams, m: int, L: Optional[float] = None, R: Optional[float] = None) -> ExpGridSpec:
    if L is None or R is None:
        dL, dR = exp_domain_mass(min(params.lam0, params.lam1), p=0.999)
        if L is None:
            L = dL
        if R is None:
            R = dR
    pts = np.linspace(L, R, m)
    return ExpGridSpec(L=float(L), R=float(R), m=m, points=pts)


def objective_J_alpha_beta_exp(alpha: float, beta: float, params: ExpParams) -> float:
    ex = 1.0 / params.lam0
    ex2 = 2.0 / (params.lam0**2)
    return 0.5 * ((1.0 - alpha) ** 2 * ex2 - 2.0 * beta * (1.0 - alpha) * ex + beta**2)


def grad_hess_J_gamma_beta_exp(gamma: float, beta: float, params: ExpParams):
    alpha = np.exp(gamma)
    ex = 1.0 / params.lam0
    ex2 = 2.0 / (params.lam0**2)

    dJ_dalpha = -(1.0 - alpha) * ex2 + beta * ex
    dJ_dbeta = -(1.0 - alpha) * ex + beta

    grad = np.array([alpha * dJ_dalpha, dJ_dbeta], dtype=float)

    d2J_dalpha2 = ex2
    d2J_dgamma2 = alpha * alpha * d2J_dalpha2 + alpha * dJ_dalpha
    d2J_dgdb = alpha * ex
    H = np.array([[d2J_dgamma2, d2J_dgdb], [d2J_dgdb, 1.0]], dtype=float)
    return grad, H, objective_J_alpha_beta_exp(alpha, beta, params)


def constraint_zeta_gamma_beta_exp(gamma: float, beta: float, grid: ExpGridSpec, params: ExpParams):
    alpha = np.exp(gamma)
    d = grid.points

    u = (d - beta) / alpha
    valid = u >= 0.0

    pf = np.zeros_like(d, dtype=float)
    base = (params.lam0 / alpha) * np.exp(-params.lam0 * u[valid])
    pf[valid] = base

    g = exp_pdf(d, params.lam1)
    zeta = pf - g

    A = np.zeros((grid.m, 2), dtype=float)
    if np.any(valid):
        uv = u[valid]
        pfv = pf[valid]
        A[valid, 0] = pfv * (params.lam0 * uv - 1.0)          # d/dgamma
        A[valid, 1] = pfv * (params.lam0 / alpha)             # d/dbeta

    return {"zeta": zeta, "A": A}

# ---- NEW: compute one KKT direction (no update here) ------------------------
def sqp_direction_exp(
    gamma, beta, lam, grid, params,
    reg_H=1e-10, reg_KKT_primal=0.0, reg_KKT_dual=1e-8
):
    """Return (d,w,g,zeta,A) where:
       d is the primal search direction in (gamma,beta),
       w is the dual direction,
       g = ∇J + A^T λ  (Lagrangian grad),
       zeta are current constraint residuals,
       A is Jacobian of constraints wrt (gamma,beta).
    """
    # Lagrangian pieces
    gJ, HJ, _ = grad_hess_J_gamma_beta_exp(gamma, beta, params)
    parts = constraint_zeta_gamma_beta_exp(gamma, beta, grid, params)
    zeta, A = parts["zeta"], parts["A"]
    g = gJ + A.T @ lam
    H = HJ

    # Regularized KKT solve
    m = grid.m
    H_reg = H + reg_H * np.eye(2)
    K = np.block([
        [H_reg + reg_KKT_primal * np.eye(2), A.T],
        [A, -reg_KKT_dual * np.eye(m)]
    ])
    rhs = -np.concatenate([g, zeta])
    sol = np.linalg.lstsq(K, rhs, rcond=None)[0]
    d = sol[:2]
    w = sol[2:]
    return d, w, g, zeta, A

# ---- Helper: merit function & its directional derivative --------------------
def merit_phi(gamma, beta, params, grid, mu):
    Jval = objective_J_alpha_beta_exp(np.exp(gamma), beta, params)
    zeta = constraint_zeta_gamma_beta_exp(gamma, beta, grid, params)["zeta"]
    return Jval + 0.5 * mu * float(zeta @ zeta)

def merit_grad_dot_dir(gamma, beta, params, grid, zeta, A, d, mu):
    # grad_phi = gradJ + mu * A^T zeta
    gradJ, _, _ = grad_hess_J_gamma_beta_exp(gamma, beta, params)
    grad_phi = gradJ + mu * (A.T @ zeta)
    return float(grad_phi @ d)

# ---- UPDATED: full solver with step-size modes ------------------------------
def sqp_solve_exp(
    params: ExpParams,
    m: int = 101,
    max_iter: int = 100,
    tol_opt: float = 1e-10,
    tol_feas: float = 1e-10,
    init_gamma: float = 0.0,
    init_beta: float = 0.0,
    step_mode: str = "trust_clip",
    trust_clip: float = 0.5,
    fixed_step_eta: float = 0.5,
    ls_mu: float = 10.0, ls_c1: float = 1e-4, ls_shrink: float = 0.5,
    ls_min_step: float = 1e-6, ls_max_backtracks: int = 25,
    reg_H: float = 1e-10, reg_KKT_primal: float = 0.0, reg_KKT_dual: float = 1e-8,
    # NEW:
    verbose: bool = False,
    print_every: int = 1,
):
    grid = make_exp_grid(params, m=m, L=None, R=None)
    gamma, beta = init_gamma, init_beta
    lam = np.zeros(grid.m)

    hist = {
        "gamma": [], "beta": [], "alpha": [], "J": [],
        "opt_res": [], "feas_res": [],
        # NEW:
        "t": [], "d_norm_inf": [], "w_norm_inf": []
    }

    for it in range(max_iter):
        alpha = np.exp(gamma)
        gJ_now, _, Jval = grad_hess_J_gamma_beta_exp(gamma, beta, params)
        parts_now = constraint_zeta_gamma_beta_exp(gamma, beta, grid, params)
        zeta_now, A_now = parts_now["zeta"], parts_now["A"]
        g_now = gJ_now + A_now.T @ lam

        hist["gamma"].append(gamma); hist["beta"].append(beta)
        hist["alpha"].append(alpha);  hist["J"].append(Jval)
        hist["opt_res"].append(np.linalg.norm(g_now, np.inf))
        hist["feas_res"].append(np.linalg.norm(zeta_now, np.inf))
        if hist["opt_res"][-1] <= tol_opt and hist["feas_res"][-1] <= tol_feas:
            break

        # 1) direction
        d, w, g, zeta, A = sqp_direction_exp(
            gamma, beta, lam, grid, params,
            reg_H=reg_H, reg_KKT_primal=reg_KKT_primal, reg_KKT_dual=reg_KKT_dual
        )

        # 2) step size
        t = 1.0
        if step_mode == "trust_clip":
            ninf = np.linalg.norm(d, np.inf)
            if ninf > max(trust_clip, 0.0):
                t = trust_clip / ninf
        elif step_mode == "fixed":
            t = float(fixed_step_eta)
        elif step_mode == "linesearch":
            phi0 = merit_phi(gamma, beta, params, grid, ls_mu)
            dir_deriv = merit_grad_dot_dir(gamma, beta, params, grid, zeta, A, d, ls_mu)
            t = 1.0; ok = False
            for _ in range(ls_max_backtracks):
                gam_try = gamma + t * d[0]; bet_try = beta + t * d[1]
                if merit_phi(gam_try, bet_try, params, grid, ls_mu) <= phi0 + ls_c1 * t * dir_deriv:
                    ok = True; break
                t *= ls_shrink
                if t < ls_min_step: break
            if not ok and t < ls_min_step: t = ls_min_step
        else:
            raise ValueError("step_mode must be one of {'trust_clip','fixed','linesearch'}")

        # --- LOG + PRINT (before updating) ---
        hist["t"].append(t)
        hist["d_norm_inf"].append(np.linalg.norm(d, np.inf))
        hist["w_norm_inf"].append(np.linalg.norm(w, np.inf))
        if verbose and (it % print_every == 0):
            print(f"it={it:03d}  mode={step_mode:<10}  t={t:.3e}  |d|_inf={hist['d_norm_inf'][-1]:.3e}  "
                  f"J={Jval:.3e}  opt={hist['opt_res'][-1]:.3e}  feas={hist['feas_res'][-1]:.3e}")

        # 3) update (scaled dual)
        gamma += t * d[0]
        beta  += t * d[1]
        lam   += t * w

    print("alpha_hat", np.exp(gamma), "beta_hat", beta)
    return {
        "gamma": gamma, "beta": beta, "alpha": np.exp(gamma),
        "lambda": lam, "grid": grid, "history": hist, "params": params
    }

params = ExpParams(lam0=0.5, lam1=1.2)

# A) Trust-clip (default)
sol = sqp_solve_exp(params, init_gamma=0.0, init_beta=0.0, m=1000, step_mode="trust_clip", trust_clip=0.25, verbose=True, print_every=20)

# B) Fixed step size
# sol = sqp_solve_exp(params, init_gamma=0.0, init_beta=0.0, m=1000, step_mode="fixed", fixed_step_eta=0.25)

# C) Backtracking line search on merit
# sol = sqp_solve_exp(
#     params, init_gamma=0.0, init_beta=0.0, m=1000, step_mode="linesearch",
#     ls_mu=10.0, ls_c1=1e-4, ls_shrink=0.5, ls_max_backtracks=25
# )

# Plot computed (SQP) map vs analytic map for Exponential→Exponential
import numpy as np
import matplotlib.pyplot as plt

# --- Problem setup ---
params = ExpParams(lam0=0.5, lam1=1.2)

# Analytic solution (affine map: alpha* = λ0/λ1, beta* = 0)
alpha_star = params.lam0 / params.lam1
beta_star  = 0.0

# Computed via SQP
# sol = sqp_solve_exp(params, m=25, max_iter=100, trust_clip=0.5)
alpha_hat, beta_hat = sol["alpha"], sol["beta"]

# --- Choose x-range ---
X_RANGE = (0.0, 6.0)
xmin, xmax = X_RANGE
xs = np.linspace(xmin, xmax, 500)

# Analytic & SQP maps
ys_analytic = alpha_star * xs + beta_star
ys_sqp      = alpha_hat * xs + beta_hat

# --- Y-range (auto) ---
ymin = min(ys_analytic.min(), ys_sqp.min())
ymax = max(ys_analytic.max(), ys_sqp.max())
pad = 0.05 * (ymax - ymin + 1e-12)
ylo, yhi = ymin - pad, ymax + pad

# --- Plot ---
plt.figure(figsize=(8, 6), dpi=120)
plt.plot(xs, ys_analytic, linewidth=2, label=f"Analytic: α*={alpha_star:.3f}, β*={beta_star:.3f}")
plt.plot(xs, ys_sqp, linestyle="--", linewidth=2, label=f"SQP: α={alpha_hat:.3f}, β={beta_hat:.3f}")
plt.xlim(xmin, xmax)
plt.ylim(ylo, yhi)
plt.xlabel("x")
plt.ylabel("y = s(x)")
plt.title("Exponential→Exponential Transport Maps: Analytic vs SQP")
plt.legend()
plt.tight_layout()

SAVE_PATH = "transport_maps_exp.png"
plt.savefig(SAVE_PATH, dpi=200)
print(f"the analytical solution for alpha, beta are {alpha_star, beta_star}")
print(f"the analytical solution for alpha, beta are {alpha_hat, beta_hat}")
plt.show()

SAVE_PATH, alpha_star, beta_star, alpha_hat, beta_hat

def pushforward_pdf_exp(d: np.ndarray, alpha: float, beta: float, lam0: float) -> np.ndarray:
    """
    Pf(s)(d) for X~Exp(lam0), s(x)=alpha x + beta.
    Uses NaN outside support so the line doesn't draw across the boundary.
    """
    u = (d - beta) / alpha
    valid = (u > 0)                 # strict > 0 avoids the boundary spike
    Pf = np.full_like(d, np.nan)    # NaN -> matplotlib won't draw there
    Pf[valid] = (lam0 / alpha) * np.exp(-lam0 * u[valid])
    return Pf

def plot_source_and_targets_exp(sol, params: ExpParams, num_pts: int = 2001, avoid_zero_eps: float = 1e-6):
    """
    Two-panel figure:
      (1) source mu(x) ~ Exp(lam0)    (x starts at epsilon, not 0)
      (2) pushforward Pf(s)(d) vs true target nu(d)  (d starts at epsilon)
    """
    import numpy as np
    import matplotlib.pyplot as plt

    alpha_hat, beta_hat = sol["alpha"], sol["beta"]

    # broad domain, then exclude the exact 0
    _, R = exp_domain_mass(params, p=0.999)
    x = np.linspace(avoid_zero_eps, R, num_pts)
    d = np.linspace(avoid_zero_eps, R, num_pts)

    mu_x = exp_pdf(x, params.lam0)
    nu_d = exp_pdf(d, params.lam1)
    pf_d = pushforward_pdf_exp(d, alpha_hat, beta_hat, params.lam0)

    fig, axes = plt.subplots(1, 2, figsize=(11, 4.2), sharey=False)

    # Left: source density
    ax = axes[0]
    ax.plot(x, mu_x, lw=2)
    ax.set_title(r"Source density $\mu(x)$")
    ax.set_xlabel("x")
    ax.set_ylabel("density")
    ax.grid(alpha=0.3)

    # Right: learned vs. true target
    ax = axes[1]
    ax.plot(d, pf_d, lw=2, label=r"Pushforward $P_f(s)(d)$")
    ax.plot(d, nu_d, "k--", lw=2, label=r"True target $\nu(d)$")
    ax.set_title("Target densities on $d$")
    ax.set_xlabel("d")
    ax.grid(alpha=0.3)
    ax.legend()

    fig.suptitle("Source vs. Learned Target vs. True Target", y=1.03, fontsize=13)
    fig.tight_layout()
    plt.show()
    return

plot_source_and_targets_exp(sol, params, avoid_zero_eps=1e-6)

